---
title: "Kaggle D1"
date: 2019-12-16 18:00:28
categories: python kaggle
---

# Medici Education Kaggle Day1(Self-Study)

머신러닝 탐구생활이라는 책을 통하여 캐글을 처음 사용해보고 머신러닝에 대해 깊게 접근하고자 이 책을 통해 공부하고 있습니다.

## Table of Contents
  1. [캐글을 시작하는 방법](#캐글을-시작하는-방법)

## 캐글을 시작하는 방법

<a name="competition_select"></a><a name="1.1"></a>
  - [1.1](#competition_select) **참여할 경진대회 선정**  
    + 처음 캐글을 접하는 시점에서 이미 종료된 과거 경진대회에 참여해서 머신러닝 경험 쌓을 예정
    + 과거 경진대회는 제출 횟수에 제한이 없는 것도 중요한 장점이다.
    + 과거 경진대회 선정시에 참고할 점
      * 해당 경진대회에 데이터 누출(Data Leakage)이 있었는지를 확인한다.
        - 데이터 누출이 있으면 유의미한 피처 엔지니어링과 알고리즘을 사용해도 상위 입상이 안될 수 있다.
      * 리더보드 상위 입상자들의 Submission 개수가 200개 이하인 경진대회에 참여를 권장한다.
        - 상위 입상자의 SUbmission 수가 높다면 대부분 신뢰할 수 있는 교차 검증 기법을 구착하기 어렵다.


<a name="competition_explain"></a><a name="1.2"></a>
  - [1.2](#competition_explain) **경진대회 푸는 과정**  
    + 데이터 이해
      * 데이터를 받아 직접 탐색해본다.
      * 데이터를 활용해 기초 통계, 단일 변수 시각화, 변수 간 관계 등 다양한 시각화를 해본다.
    + 평가 척도 이해
      * 경진대회의 평가 척도를 이해한다.(문제 의도를 이해)
    + 교차 검증 기법 선정
      * 일반적인 교차 검즘 방법
        - 제공된 데이터를 5:5 ~ 9:1 비율로 훈련/검증 데이터로 분리한다.
        - 훈련 데이터에 머신러닝 모델을 학습하고, 검증 데이터에서 평가 척도 점수를 구한다.
        - 1~2번을 10번 반복해 검증 데이터의 평균을 구한다.
      * 알아두면 좋은 점
        - 데이터가 매우 크다면 5:5, 적을 경우에는 9:1이 좋다. 데이터를 분리할 때 재현성을 위해 random_seed 값을 고정한다.
    + 피처 엔지니어링
      * 변수값 스케일링, 이상값 제거, 결측치 대체, 범주형 데이터 변환, 변수 선정, 파생 변수 생성 등 머신러닝 모델이 확인하기 쉽도록 만들어준다.
      * 피처 엔지니어링은 Tabular 데이터 기반 경진대회의 랭킹을 가르는 가장 중요한 요인
    + 모델 튜닝
      * 머신러닝 모델의 최적 파라미터를 찾는다.
      * 중간 결과를 매번 저장해야 한다.
    + 앙상블
      * 하나의 모델보다 다수의 모델을 앙상블 했을 경우가 더 나은 성능을 보인다. 그 중에서도 서로 다른 유형의 모델을 앙상블 하는 경우가 가장 좋은 효과를 나타낸다.
      * 다수 계층의 모델을 학습하는 스태킹도 캐글에 자주 사용되는 기법이다.
      
  
**[⬆ back to top](#table-of-contents)**
