---
title: "Python D5"
date: 2019-12-09 20:08:28
categories: python
---

# Medici Education Python Day5

## Table of Contents
  1. [BeautifulSoup](#beautifulsoup)
  1. [웹 크롤링](#웹-크롤링)
  1. [pandas](#pandas)
  1. [웹 크롤링 실습](#웹-크롤링-실습)

  
## BeautifulSoup

<a name="beautifulsoup"></a><a name="1.1"></a>
  - [1.1](#beautifulsoup) **BeautifulSoup 소개**  
    + HTML과 XML 파일로부터 데이터를 뽑아내기 위한 파이썬 라이브러리  
    + 터미널에서 pip를 사용하여 설치
    
```python
# pip install beautifulsoup4
```

<a name="beautifulsoup--use"></a><a name="1.2"></a>
  - [1.2](#beautifulsoup--use) **BeautifulSoup 사용 하기**
    + findAll()과 find()는 가장 자주 쓰이는 함수 입니다.
    + HTML 페이지에서 원하는 태그를 쉽게 필터링 할 수 있습니다.
    
```python
import bs4

html = """
<!DOCTYPE html>
<html>
   <head>
       <title>웹 크롤링 실습</title>
   </head>
<body>
   <h1 class="green">1. 웹 크롤링 실습 페이지 입니다.</h1>
   <h1 class="red">2. 웹 크롤링 실습 페이지 입니다.</h1>
   <p>웹 크롤링 실습 p 태그 입니다.</p>
</body>
</html>"""

bs4_object = bs4.BeautifulSoup(html, "html.parser")
print(bs4_object.find("h1"))                            # <h1 class="green">1. 웹 크롤링 실습 페이지 입니다.</h1>
print(bs4_object.find("h1").text)                       # 1. 웹 크롤링 실습 페이지 입니다.
h1_tags = bs4_object.findAll("h1")
print(h1_tags)                                          # [<h1 class="green">1. 웹 크롤링 실습 페이지 입니다.</h1>, <h1 class="red">2. 웹 크롤링 실습 페이지 입니다.</h1>]
for tag in h1_tags:
    print(tag.text)                                     # 1. 웹 크롤링 실습 페이지 입니다.
                                                        # 2. 웹 크롤링 실습 페이지 입니다.
print(h1_tags[0])                                       # <h1 class="green">1. 웹 크롤링 실습 페이지 입니다.</h1>
print(h1_tags[0].text)                                  # 1. 웹 크롤링 실습 페이지 입니다.

# 클래스가 red인 h1 태그 찾기
h1_tag_red = bs4_object.find("h1", {"class":"red"})
print(h1_tag_red)                                           # <h1 class="red">2. 웹 크롤링 실습 페이지 입니다.</h1>
print(h1_tag_red.text)                                      # 2. 웹 크롤링 실습 페이지 입니다.

# 클래스가 red거나 green인 h1 태그 찾기
h1_tag_red_green = bs4_object.find("h1", {"class": {"red", "green"}})
print(h1_tag_red_green)                                                     # <h1 class="green">1. 웹 크롤링 실습 페이지 입니다.</h1>
print(h1_tag_red_green.text)                                                # 1. 웹 크롤링 실습 페이지 입니다.


h1_tags_red_green = bs4_object.findAll("h1", {"class": {"red", "green"}})
print(h1_tags_red_green)                                                    # [<h1 class="green">1. 웹 크롤링 실습 페이지 입니다.</h1>, <h1 class="red">2. 웹 크롤링 실습 페이지 입니다.</h1>]
for tag in h1_tags_red_green:
    print(tag.text)                                                         # 1. 웹 크롤링 실습 페이지 입니다.
                                                                            # 2. 웹 크롤링 실습 페이지 입니다.    
```
    
**[⬆ back to top](#table-of-contents)**

## 웹 크롤링

<a name="naver-crawling"></a><a name="2.1"></a>
  - [2.1](#naver-crawling) **네이버 홈페이지 크롤링 하기**  
  
```python
import requests
import bs4

html = requests.get("https://www.naver.com/")
print(html.status_code)
if html.status_code == 200:
    print("정상페이지")
    print("*"*50)
    bs4_object = bs4.BeautifulSoup(html.text, "html.parser")
    # print(bs4_object)
    li_tags = bs4_object.findAll("li", {"class":"ca_item"})
    for tag in li_tags:
        print(tag.text)
else:
    print("오류페이지")
```
![python-d5-01](https://user-images.githubusercontent.com/50984551/70427436-0e090c00-1ab8-11ea-838d-ce0ac46589f0.png)


<a name="weather-crawling"></a><a name="2.2"></a>
  - [2.2](#weather-crawling) **네이버 날씨 크롤링 하기**  


![python-d5-02](https://user-images.githubusercontent.com/50984551/70427969-0302ab80-1ab9-11ea-97dc-d6e7921e87ff.png)

```python
import requests
import bs4

def temperature(local):
    html = requests.get("https://search.naver.com/search.naver?query={} 날씨".format(local))
    bs4_object = bs4.BeautifulSoup(html.text, "html.parser")
    address = bs4_object.find("span", {"class":"btn_select"})
    print(address.text)
    temper = bs4_object.find("span", {"class": "todaytemp"})
    print("{}도 입니다.".format(temper.text))

    indicator_tag = bs4_object.find("dl", {"class": "indicator"})
    # print(indicator_tag)
    dd_tags = indicator_tag.findAll("span", {"class": "num"})
    dt_tags = indicator_tag.findAll("dt")
    for ti, wt in zip(dt_tags, dd_tags):
        print("{} : {}".format(ti.text, wt.text))
    print("*"*30)


add = ["앙천구", "강남구", "관악구"]
for address in add:
    temperature(address)
```

![python-d5-03](https://user-images.githubusercontent.com/50984551/70427986-0e55d700-1ab9-11ea-8f47-7114f69846f3.png)

<a name="webtoon-crawling"></a><a name="2.3"></a>
  - [2.3](#webtoon-crawling) **네이버 웹툰 크롤링 하기**  

![python-d5-04](https://user-images.githubusercontent.com/50984551/70428164-612f8e80-1ab9-11ea-95b0-765b889f174a.png)

``` python
import requests
import bs4

html = requests.get("https://comic.naver.com/webtoon/weekday.nhn")
bs4_object = bs4.BeautifulSoup(html.text, "html.parser")
# print(bs4_object)

webtoon_all_tag = bs4_object.find("div", {"class":"list_area daily_all"})
# print(webtoon_all_tag)
for webtoon in webtoon_all_tag.findAll("li"):
    print(webtoon.find("a", {"class":"title"}).text)
    print(webtoon.find("img")["src"])
```

![python-d5-05](https://user-images.githubusercontent.com/50984551/70428310-b10e5580-1ab9-11ea-8e62-11f204579616.png)

**[⬆ back to top](#table-of-contents)**

## pandas

<a name="pandas"></a><a name="3.1"></a>
  - [3.1](#pandas) **pandas**  
    + 데이터 분석을 위해 자주 사용되는 라이브러리
    + 행과 열로 이루어진 데이터 객체를 만들어 사용한다.
    + csv파일 사용에 편리하다.
    
<a name="pandas_df"></a><a name="3.2"></a>
  - [3.2](#pandas_df) **DataFrame**  
    + 2차원 자료구조
    + 행과 열이 있는 테이블 데이터
    + Dictionary 데이터를 DataFrame으로 변환 가능

```python
import pandas as pd

data = {
    "국어" : [10, 20, 30, 40],
    "수학" : [50, 60, 70, 80],
    "영어" : [100, 10, 20, 30]
}

df = pd.DataFrame(data)
print(df)
```
![python-d5-06](https://user-images.githubusercontent.com/50984551/70429396-cdab8d00-1abb-11ea-95bc-d1167ef393af.png)

<a name="pandas_webtoon"></a><a name="3.3"></a>
  - [3.3](#pandas_webtoon) **네이버 웹툰 크롤링 후 DataFrame으로 저장하기**  

```python
import requests
import bs4

webtoon_title = []
webtoon_img = []
webtoon_writer = []


def naver_webtoon_yoil(yoil):
    html = requests.get("https://comic.naver.com/webtoon/weekdayList.nhn?week={}".format(yoil))
    bs4_object = bs4.BeautifulSoup(html.text, "html.parser")
    # print(bs4_object)

    webtoon_all_tag = bs4_object.find("div", {"class":"list_area daily_img"})
    # print(webtoon_all_tag)
    for webtoon in webtoon_all_tag.findAll("li"):
        webtoon_title.append(webtoon.find("a")["title"])
        webtoon_img.append(webtoon.find("img")["src"])
        webtoon_writer.append(webtoon.find("dd").text.replace('\n', ''))
        print(webtoon.find("a")["title"])
        # print(webtoon.find("dt").text)        # 제목이 잘리도록 설정되어 있다.
        print(webtoon.find("dd").text.replace('\n', ''))
        print(webtoon.find("strong").text)
        print(webtoon.find("img")["src"])
        # is_update = webtoon.find("em", {"class":{"ico_updt", "ico_break"}})
        # if is_update != None:
        #     print()
        print()


weekend = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]
for day in weekend:
    naver_webtoon_yoil(day)


html = """
<!doctype html>
<html lang="ko">
   <head>
   <meta charset="utf-8">
      <title>HTML</title>
   </head>
   <body>"""

for title, img in zip(webtoon_title, webtoon_img):
    html += "<img src=\"" + img + "\">" + title + "</img>\n"

html += """
   </body>
</html>
"""

file = open("webtoon.html", "w", encoding="UTF-8")
file.write(html)
file.close()



import pandas as pd

data = {
    "제목" : webtoon_title,
    "작가" : webtoon_writer,
    "이미지": webtoon_img
}

webtoon_data = pd.DataFrame(data)
print(webtoon_data)
# webtoon_data.to_csv("webtoon_data.csv")

df = pd.read_csv("webtoon_data.csv", index_col=0)
print(df)
```

**[⬆ back to top](#table-of-contents)**

## 웹 크롤링 실습

<a name="innogov_crawling"></a><a name="4.1"></a>
  - [4.1](#innogov_crawling) **정부혁신 1번가 사이트 크롤링 해보기**  

![python-d5-07](https://user-images.githubusercontent.com/50984551/70429829-c638b380-1abc-11ea-87ff-c164035aef36.png)

```python
import requests
import bs4

innogov_title = []
innogov_contents = []

def innogov(page):
    html = requests.get("https://www.innogov.go.kr/ucms/bbs/B0000042/list.do?sort=02&searchCnd=1&searchWrd=&pageIndex={}&menuNo=300125".format(page))
    bs4_object = bs4.BeautifulSoup(html.text, "html.parser")
    # print(bs4_object)

    title_tags = bs4_object.findAll("td", {"class":"tit"})
    if len(title_tags):
        for tag in title_tags:
            print(tag.text)

            # print(tag.find("a")["href"])
            try:
                inner_url = tag.find("a")["href"]
                inner_html = requests.get("https://www.innogov.go.kr" + inner_url)
                inner_object = bs4.BeautifulSoup(inner_html.text, "html.parser")
                # print(bs4_detailed)
                print(inner_object.find("div", {"class":"dbData"}).text)
                innogov_contents.append(inner_object.find("div", {"class":"dbData"}).text)
                innogov_title.append(tag.text)
            except:
                print("오류 : ", tag.text)
        return False
    else:
        return True


def innogov_page():
    page_num = 1
    while True:
        if innogov(page_num):
            break
        page_num += 1


innogov_page()


import pandas as pd

data = {
    "제목": innogov_title,
    "내용": innogov_contents
}

innogov_data = pd.DataFrame(data)
innogov_data.to_csv("innogov.csv")

df = pd.read_csv("innogov.csv", index_col=0)
print(df)
```

![python-d5-08](https://user-images.githubusercontent.com/50984551/70430084-5545cb80-1abd-11ea-9bae-dce76edbe19f.png)

**[⬆ back to top](#table-of-contents)**



















